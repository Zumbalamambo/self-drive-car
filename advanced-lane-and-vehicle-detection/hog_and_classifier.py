import globimport pickleimport timeimport cv2 as cvimport matplotlib.image as mpimgimport matplotlib.pyplot as pltimport numpy as npfrom scipy.ndimage.measurements import labelfrom skimage.feature import hogfrom sklearn.metrics import accuracy_scorefrom sklearn.model_selection import train_test_split, GridSearchCVfrom sklearn.preprocessing import StandardScalerfrom sklearn.svm import SVCfrom sklearn.utils import shuffledef add_heat(heatmap, bbox_list):    # Iterate through list of bboxes    for box in bbox_list:        # Add += 1 for all pixels inside each bbox        # Assuming each "box" takes the form ((x1, y1), (x2, y2))        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1    # Return updated heatmap    return heatmap  # Iterate through list of bboxesdef apply_threshold(heatmap, threshold):    # Zero out pixels below the threshold    heatmap[heatmap <= threshold] = 0    # Return thresholded map    return heatmapdef draw_labeled_bboxes(img, labels):    # Iterate through all detected cars    for car_number in range(1, labels[1] + 1):        # Find pixels with each car_number label value        nonzero = (labels[0] == car_number).nonzero()        # Identify x and y values of those pixels        nonzeroy = np.array(nonzero[0])        nonzerox = np.array(nonzero[1])        # Define a bounding box based on min/max x and y        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))        # Draw the box on the image        cv.rectangle(img, bbox[0], bbox[1], (0, 0, 255), 6)    # Return the image    return img# Define a function to compute binned color featuresdef bin_spatial(img=mpimg.imread("/Users/siddiqui/Downloads/advanced-lane-detection-data/cutouts/cutout1.jpg"),                size=(32, 32)):    """    1- downsize the image    2- get feature vector using ravel    """    color1 = cv.resize(img[:, :, 0], size).ravel()    color2 = cv.resize(img[:, :, 1], size).ravel()    color3 = cv.resize(img[:, :, 2], size).ravel()    return np.hstack((color1, color2, color3))def color_hist(img=mpimg.imread("/Users/siddiqui/Downloads/advanced-lane-detection-data/cutouts/cutout1.jpg"),               nbins=32,               bins_range=(0, 256),               with_visualization=False):    """    finding histogram of colors    1- use np.histogram to find histogram of r, g and b channels    2- concatenate all 3 histograms --> histogram features    3- find bin centers    """    # Compute the histogram of the color channels separately    r, g, b = img[:, :, 0], img[:, :, 1], img[:, :, 2]    r_hist = np.histogram(r, bins=nbins)    g_hist = np.histogram(g, bins=nbins)    b_hist = np.histogram(b, bins=nbins)    hist_features = np.concatenate((r_hist[0], g_hist[0], b_hist[0]))    bin_edges = r_hist[1]    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges) - 1]) / 2    if with_visualization:        # Plot a figure with all three bar charts        plt.figure(figsize=(12, 4))        plt.subplot(131)        plt.bar(bin_centers, r_hist[0])        plt.xlim(0, 256)        plt.title('R Histogram')        plt.subplot(132)        plt.bar(bin_centers, g_hist[0])        plt.xlim(0, 256)        plt.title('G Histogram')        plt.subplot(133)        plt.bar(bin_centers, b_hist[0])        plt.xlim(0, 256)        plt.title('B Histogram')        cv.imshow("image", cv.cvtColor(img, cv.COLOR_RGB2BGR))        plt.show()    # Return the individual histograms, bin_centers and feature vector    return hist_features# Define a function to return HOG features and visualizationdef get_hog_features(img, orient, pix_per_cell, cell_per_block,                     vis=False, feature_vec=True):    """    finding histogram of gradient    """    # Call with two outputs if vis==True    if vis is True:        hist_features, hog_image = hog(img,                                       orientations=orient,                                       pixels_per_cell=(pix_per_cell, pix_per_cell),                                       cells_per_block=(cell_per_block, cell_per_block),                                       transform_sqrt=False,                                       visualise=vis,                                       feature_vector=feature_vec)        return hist_features, hog_image    # Otherwise call with one output    else:        hist_features = hog(img,                            orientations=orient,                            pixels_per_cell=(pix_per_cell, pix_per_cell),                            cells_per_block=(cell_per_block, cell_per_block),                            transform_sqrt=False,                            visualise=vis,                            feature_vector=feature_vec)        return hist_featuresdef change_cspace(img, cspace):    feature_image = []    if cspace != 'RGB':        if cspace == 'HSV':            feature_image = cv.cvtColor(img, cv.COLOR_RGB2HSV)        elif cspace == 'LUV':            feature_image = cv.cvtColor(img, cv.COLOR_RGB2LUV)        elif cspace == 'HLS':            feature_image = cv.cvtColor(img, cv.COLOR_RGB2HLS)        elif cspace == 'YUV':            feature_image = cv.cvtColor(img, cv.COLOR_RGB2YUV)        elif cspace == 'YCrCb':            feature_image = cv.cvtColor(img, cv.COLOR_RGB2YCrCb)    else:        feature_image = np.copy(img)    return feature_imagedef convert_color(img, conv='RGB2YCrCb'):    if conv == 'RGB2YCrCb':        return cv.cvtColor(img, cv.COLOR_RGB2YCrCb)    if conv == 'BGR2YCrCb':        return cv.cvtColor(img, cv.COLOR_BGR2YCrCb)    if conv == 'RGB2LUV':        return cv.cvtColor(img, cv.COLOR_RGB2LUV)def extract_single_img_features(img,                                spatial_size=(32, 32),                                hist_bins=32,                                cspace='RGB',                                hist_range=(0, 256),                                orient=9,                                pix_per_cell=8, cell_per_block=2,                                hog_channel=0,                                with_spatial_feature=True,                                with_color_feature=True,                                with_gradient_feature=True                                ):    """    combine spatial bin, color histogram and gradient histogram features for a single image    """    # Create a list to append feature vectors to    features = []    # apply color conversion if other than 'RGB'    feature_image = change_cspace(img, cspace)    # get hog features for either specific channel or for all channels    if with_gradient_feature is True:        if hog_channel == 'ALL':            hog_features = []            channels = feature_image.shape[2]            # get features for all 3 channels            for channel in range(channels):                hog_features.append(get_hog_features(feature_image[:, :, channel],                                                     orient, pix_per_cell, cell_per_block,                                                     feature_vec=True, vis=False))            hog_features = np.ravel(hog_features)        else:            # get features for specific channel            hog_features = get_hog_features(feature_image[:, :, hog_channel],                                            orient, pix_per_cell, cell_per_block,                                            vis=False, feature_vec=True)    else:        hog_features = []    # Apply bin_spatial() to get spatial color features    bin_features = bin_spatial(feature_image) if with_spatial_feature is True else []    # Apply color_hist() to get color histogram features    color_hist_features = color_hist(feature_image) if with_color_feature is True else []    # concatenate all 3 types of features    feature = np.concatenate((bin_features, color_hist_features, hog_features), axis=0)    # Append the new feature vector to the features list    features.append(feature)    # Return list of feature vectors    return featuresdef extract_features(imgs,                     spatial_size=(32, 32),                     hist_bins=32,                     cspace='RGB',                     hist_range=(0, 256),                     orient=9,                     pix_per_cell=8, cell_per_block=2, hog_channel=0                     ):    """    combine spatial bin, color histogram and gradient histogram features    """    # Create a list to append feature vectors to    features = []    # Iterate through the list of images    for img_file in imgs:        # Read in each one by one        img = mpimg.imread(img_file)        # apply color conversion if other than 'RGB'        feature_image = change_cspace(img, cspace)        # get hog features for either specific channel or for all channels        if hog_channel == 'ALL':            hog_features = []            # get features for all 3 channels            for channel in range(feature_image.shape[2]):                hog_features.append(get_hog_features(feature_image[:, :, channel],                                                     orient, pix_per_cell, cell_per_block,                                                     feature_vec=True, vis=False))            hog_features = np.ravel(hog_features)        else:            # get features for specific channel            hog_features = get_hog_features(feature_image[:, :, hog_channel],                                            orient, pix_per_cell, cell_per_block,                                            vis=False, feature_vec=True)        # Apply bin_spatial() to get spatial color features        bin_features = bin_spatial(feature_image)        # Apply color_hist() to get color histogram features        color_hist_features = color_hist(feature_image)        # concatenate all 3 types of features        feature = np.concatenate((bin_features, color_hist_features, hog_features), axis=0)        # Append the new feature vector to the features list        features.append(feature)    # Return list of feature vectors    return featuresdef search_windows(img,                   windows,                   clf,                   scaler,                   color_space='RGB',                   spatial_size=(32, 32),                   hist_bins=32,                   hist_range=(0, 256),                   orient=9,                   pix_per_cell=8,                   cell_per_block=2,                   hog_channel=0,                   spatial_feat=True,                   hist_feat=True,                   hog_feat=True):    # 1) Create an empty list to receive positive detection windows    on_windows = []    # 2) Iterate over all windows in the list    for window in windows:        # 3) Extract the test window from original image        test_img = cv.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))        # 4) Extract features for that window        features = extract_single_img_features(test_img,                                               cspace=color_space,                                               spatial_size=spatial_size,                                               hist_bins=hist_bins,                                               orient=orient,                                               pix_per_cell=pix_per_cell,                                               cell_per_block=cell_per_block,                                               hog_channel=hog_channel,                                               with_spatial_feature=spatial_feat,                                               with_color_feature=hist_feat,                                               with_gradient_feature=hog_feat)        # 5) Scale extracted features to be fed to classifier        test_features = scaler.transform(np.array(features).reshape(1, -1))        # 6) Predict using your classifier        prediction = clf.predict(test_features)        # 7) If positive (prediction == 1) i.e. car, then save the window        if prediction == 1:            on_windows.append(window)    # 8) Return windows for positive detections    return on_windowsdef get_slide_windows(img,                      x_start_stop=[None, None],                      y_start_stop=[None, None],                      xy_window=(64, 64),                      xy_overlap=(0.5, 0.5)):    # If x and/or y start/stop positions not defined, set to image size    img_width, img_height = img.shape[1], img.shape[0]    if x_start_stop[0] is None:        x_start_stop[0] = 0    if x_start_stop[1] is None:        x_start_stop[1] = img_width    if y_start_stop[0] is None:        y_start_stop[0] = 0    if y_start_stop[1] is None:        y_start_stop[1] = img_height    # Compute the span of the region to be searched    xy_span = (x_start_stop[1] - x_start_stop[0],               y_start_stop[1] - y_start_stop[0])    # Compute the number of pixels per step in x/y    n_pixels_per_step = (np.int(xy_window[0] * (1 - xy_overlap[0])),                         np.int(xy_window[1] * (1 - xy_overlap[1])))    # Compute the number of windows in x/y    n_buffer = (np.int(xy_window[0] * (xy_overlap[0])),                np.int(xy_window[1] * (xy_overlap[1])))    n_windows = (np.int((xy_span[0] - n_buffer[0]) / n_pixels_per_step[0]),                 np.int((xy_span[1] - n_buffer[1]) / n_pixels_per_step[1]))    # Initialize a list to append window positions to    window_list = []    # Loop through finding x and y window positions    for ys in range(n_windows[1]):        for xs in range(n_windows[0]):            # Calculate each window position            xy_start = (xs * n_pixels_per_step[0] + x_start_stop[0],                        ys * n_pixels_per_step[1] + y_start_stop[0])            xy_stop = (xy_start[0] + xy_window[0],                       xy_start[1] + xy_window[1])            # Append window position to list            window_list.append(((xy_start[0], xy_start[1]),                                (xy_stop[0], xy_stop[1])))    # Return the list of windows    return window_listdef define_classifier(spatial_size, hist_bins, colorspace, hist_range,                      orient, pix_per_cell, cell_per_block, hog_channel, path, return_pre_trained=False,                      return_trained=False):    if return_pre_trained:        data = pickle.load(open('trained-clf.p', 'rb'))        return data["clf"], data["x_scaler"]    imgs_cars = glob.glob(path)    cars_files = []    not_cars_files = []    for img_file in imgs_cars:        if 'image' in img_file or 'extra' in img_file:            not_cars_files.append(img_file)        else:            cars_files.append(img_file)    # features    car_features = extract_features(cars_files, spatial_size, hist_bins, colorspace, hist_range,                                    orient, pix_per_cell, cell_per_block, hog_channel)    not_cars_features = extract_features(not_cars_files, spatial_size, hist_bins, colorspace, hist_range,                                         orient, pix_per_cell, cell_per_block, hog_channel)    # normalized features    features = np.vstack((car_features, not_cars_features)).astype(np.float64)    x_scaler = StandardScaler().fit(features)    # features and labels    features = x_scaler.transform(features)    labels = np.hstack((np.ones(len(cars_files)), np.zeros(len(not_cars_files))))    # split dataset    features, labels = shuffle(features, labels)    test_size = 0.0 if return_trained is True else 0.2    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)    # initialize SVM with optimized params using GridSearchCV    params = {'kernel': ('linear', 'rbf'), 'C': [1, 10]}    svr = SVC()    clf = GridSearchCV(svr, params)    # train the classifier    t_train_start = time.time()    clf.fit(x_train, y_train)    t_train_end = time.time()    print("best params: {}".format(clf.best_params_))    pickle.dump({"clf": clf, "x_scaler": x_scaler}, open('trained-clf.p', 'wb'))    if return_trained is True:        return clf, x_scaler        # prediction using classifier    y_predict = clf.predict(x_test)    score = accuracy_score(y_test, y_predict)    # accuracy check of classifier    print("train time: {:.2f}s".format(t_train_end - t_train_start))    print("score: {:.3f}%".format(score * 100))def run_classifier():    h_bins, spatial = 9, 9    hist_range = (0, 256)    cspace = 'RGB'  # Can be RGB, HSV, LUV, HLS, YUV, YCrCb    orient = 6  # Can be 6, 9, 12    pix_per_cell = 8    cell_per_block = 8    hog_channel = 'ALL'  # Can be 0, 1, 2, or "ALL"    define_classifier(spatial, h_bins, cspace, hist_range,                      orient, pix_per_cell, cell_per_block, hog_channel,                      "/Users/siddiqui/Downloads/data-set/**/**/*.jpeg")def search_and_classify():    # hyper-parameters    spatial, h_bins, hist_range = (32, 32), 32, (0, 256)    cspace = 'RGB'  # Can be RGB, HSV, LUV, HLS, YUV, YCrCb    orient = 6  # Can be 6, 9, 12    pix_per_cell = 8    cell_per_block = 2    hog_channel = 0  # Can be 0, 1, 2, or "ALL"    xy_window = (96, 96)    xy_overlap = (0.5, 0.5)    with_spatial_feature = True    with_color_feature = True    with_gradient_feature = True    training_samples = "/Users/siddiqui/Downloads/advanced-lane-detection-data/data-set/**/**/*.jpeg"    # get the trained classifier    clf, x_scaler = define_classifier(spatial, h_bins, cspace, hist_range,                                      orient, pix_per_cell, cell_per_block, hog_channel,                                      training_samples, True, True)    imgs = glob.glob(        "/Users/siddiqui/Documents/Projects/self-drive/CarND-Advanced-Lane-Lines/buffer/binary-original-*.jpg")    for filename in imgs:        # get an image to search and predict        image = mpimg.imread(filename)        heat = np.zeros_like(image[:, :, 0]).astype(np.float)        # update y boundaries to search for lower half only        y_start_top = [np.int(image.shape[0] / 2), None]        # get windows        windows = get_slide_windows(image,                                    y_start_stop=y_start_top,                                    xy_window=xy_window,                                    xy_overlap=xy_overlap)        # search window in the image        hot_windows = search_windows(image, windows, clf, x_scaler, cspace,                                     spatial, h_bins, hist_range, orient, pix_per_cell, cell_per_block,                                     hog_channel, with_spatial_feature, with_color_feature, with_gradient_feature)        # Add heat to each box in box list        heat = add_heat(heat, hot_windows)        # Apply threshold to help remove false positives        heat = apply_threshold(heat, 1)        # Visualize the heatmap when displaying        heatmap = np.clip(heat, 0, 255)        # Find final boxes from heatmap using label function        labels = label(heatmap)        draw_img = draw_labeled_bboxes(np.copy(image), labels)        plt.imshow(draw_img)        plt.pause(0.00001)    plt.show()search_and_classify()